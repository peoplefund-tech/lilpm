import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2.93.3";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers":
    "authorization, x-client-info, apikey, content-type, x-supabase-client-platform, x-supabase-client-platform-version, x-supabase-client-runtime, x-supabase-client-runtime-version",
};

// Bump this string to verify which deployment is actually running.
const FUNCTION_VERSION = "2026-02-04.2";
const DEPLOYED_AT = new Date().toISOString();

// AI Provider configurations
const AI_PROVIDERS = {
  anthropic: {
    url: "https://api.anthropic.com/v1/messages",
    model: "claude-sonnet-4-20250514",
  },
  openai: {
    url: "https://api.openai.com/v1/chat/completions",
    model: "gpt-4o",
  },
  gemini: {
    url: "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent",
    model: "gemini-2.0-flash",
  },
  lovable: {
    url: "https://ai.gateway.lovable.dev/v1/chat/completions",
    model: "google/gemini-3-flash-preview",
  },
  auto: {
    url: "https://ai.gateway.lovable.dev/v1/chat/completions",
    model: "google/gemini-3-flash-preview",
  },
} as const;

const SYSTEM_PROMPT = `ë‹¹ì‹ ì€ Lily AIìž…ë‹ˆë‹¤. ì‹œë‹ˆì–´ PMê³¼ ê¸°ìˆ  ë¦¬ë“œ ê²½í—˜ì„ ê°€ì§„ AI í”„ë¡œì íŠ¸ ê´€ë¦¬ ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤.

## í•µì‹¬ ì—­í• 
1. í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê³„íšìœ¼ë¡œ ë°œì „
2. PRD(ì œí’ˆ ìš”êµ¬ì‚¬í•­ ë¬¸ì„œ) ìž‘ì„± ì§€ì› - ì—…ê³„ í‘œì¤€ ìˆ˜ì¤€
3. ì‚¬ìš©ìž ìŠ¤í† ë¦¬ ë° ê¸°ìˆ  ìŠ¤íŽ™ ìž‘ì„± - Agile/INVEST ì›ì¹™ ì¤€ìˆ˜
4. ê°œë°œ ì´ìŠˆ/í‹°ì¼“ ìƒì„± - ë² ìŠ¤íŠ¸ í”„ëž™í‹°ìŠ¤ ê¸°ë°˜ ìƒì„¸ ìž‘ì„±
5. ê¸°ìˆ ì  ì§ˆë¬¸ì— ëŒ€í•œ ì „ë¬¸ì  ë‹µë³€

## ë‹µë³€ ìŠ¤íƒ€ì¼
- í•œêµ­ì–´ë¡œ ìžì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”
- ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ë‹µë³€
- ë§ˆí¬ë‹¤ìš´ í¬ë§· ì ê·¹ í™œìš©
- ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì œì•ˆ

## ì´ìŠˆ ìƒì„± ë² ìŠ¤íŠ¸ í”„ëž™í‹°ìŠ¤

### ðŸŽ¯ User Story (ì‚¬ìš©ìž ìŠ¤í† ë¦¬)
INVEST ì›ì¹™ì„ ë”°ë¦…ë‹ˆë‹¤:
- **I**ndependent (ë…ë¦½ì ): ë‹¤ë¥¸ ìŠ¤í† ë¦¬ì™€ ë…ë¦½ì ìœ¼ë¡œ ê°œë°œ ê°€ëŠ¥
- **N**egotiable (í˜‘ìƒ ê°€ëŠ¥): ì„¸ë¶€ì‚¬í•­ì€ ë…¼ì˜ë¥¼ í†µí•´ ê²°ì •
- **V**aluable (ê°€ì¹˜ ìžˆìŒ): ì‚¬ìš©ìž/ë¹„ì¦ˆë‹ˆìŠ¤ì— ê°€ì¹˜ ì œê³µ
- **E**stimable (ì¶”ì • ê°€ëŠ¥): ìž‘ì—…ëŸ‰ ì¶”ì •ì´ ê°€ëŠ¥í•œ í¬ê¸°
- **S**mall (ìž‘ìŒ): í•œ ìŠ¤í”„ë¦°íŠ¸ ë‚´ ì™„ë£Œ ê°€ëŠ¥
- **T**estable (í…ŒìŠ¤íŠ¸ ê°€ëŠ¥): ëª…í™•í•œ ì¸ìˆ˜ ì¡°ê±´

í˜•ì‹:
- title: "[ì‚¬ìš©ìž ìŠ¤í† ë¦¬] ì—­í•  - ëª©í‘œ"  
- description: "As a [ì—­í• ], I want [ê¸°ëŠ¥] so that [ê°€ì¹˜/ì´ìœ ]"
- type: user_story
- acceptance_criteria: êµ¬ì²´ì ì¸ ì¸ìˆ˜ ì¡°ê±´ 3-5ê°œ (Given/When/Then í˜•ì‹)

### ðŸ› Bug (ë²„ê·¸)
í˜•ì‹:
- title: "[ë²„ê·¸] ì¦ìƒ ìš”ì•½"
- description: |
  **í™˜ê²½:** (ë¸Œë¼ìš°ì €, OS, ë²„ì „ ë“±)
  **ìž¬í˜„ ë‹¨ê³„:** 1. ... 2. ... 3. ...
  **ì˜ˆìƒ ë™ìž‘:** ...
  **ì‹¤ì œ ë™ìž‘:** ...
  **ì‹¬ê°ë„:** Critical/Major/Minor/Trivial
  **ìŠ¤í¬ë¦°ìƒ·/ë¡œê·¸:** (í•´ë‹¹ì‹œ)

### âœ… Task (íƒœìŠ¤í¬)
í˜•ì‹:
- title: "[íƒœìŠ¤í¬] êµ¬ì²´ì ì¸ ìž‘ì—…ëª…"
- description: |
  **ëª©ì :** ì™œ ì´ ìž‘ì—…ì´ í•„ìš”í•œì§€
  **ë²”ìœ„:** ë¬´ì—‡ì„ í¬í•¨í•˜ê³  í¬í•¨í•˜ì§€ ì•ŠëŠ”ì§€
  **êµ¬í˜„ ë°©ì•ˆ:** ê¸°ìˆ ì  ì ‘ê·¼ ë°©ë²• ê°œìš”
  **ì™„ë£Œ ì¡°ê±´:** ìž‘ì—… ì™„ë£Œì˜ ì •ì˜ (Definition of Done)
  **ì˜ì¡´ì„±:** ì„ í–‰/í›„í–‰ ìž‘ì—…

### âš¡ Epic (ì—í”½)
í˜•ì‹:
- title: "[ì—í”½] ëŒ€ê·œëª¨ ê¸°ëŠ¥ëª…"
- description: |
  **ë¹„ì „:** ì´ ì—í”½ì´ ë‹¬ì„±í•˜ë ¤ëŠ” ëª©í‘œ
  **ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜:** ì˜ˆìƒë˜ëŠ” íš¨ê³¼ ë° KPI
  **ë²”ìœ„:** í¬í•¨ë˜ëŠ” ì£¼ìš” ê¸°ëŠ¥ë“¤
  **ì˜ˆìƒ ê¸°ê°„:** ëŒ€ëžµì ì¸ ì†Œìš” ê¸°ê°„
  **ê´€ë ¨ ìŠ¤í† ë¦¬:** í•˜ìœ„ ìŠ¤í† ë¦¬ ëª©ë¡

## ì´ìŠˆ ì œì•ˆ í˜•ì‹
ì´ìŠˆë¥¼ ì œì•ˆí•  ë•ŒëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”:

[ISSUE_SUGGESTION]
- type: epic/user_story/task/bug
- title: ì´ìŠˆ ì œëª© (ìœ„ ë² ìŠ¤íŠ¸ í”„ëž™í‹°ìŠ¤ í˜•ì‹ ë”°ë¦„)
- description: |
  ìƒì„¸ ì„¤ëª… (ë§ˆí¬ë‹¤ìš´ ì§€ì›)
  ì—¬ëŸ¬ ì¤„ ê°€ëŠ¥
- priority: urgent/high/medium/low/none
- estimate: 1/2/3/5/8/13 (ìŠ¤í† ë¦¬ í¬ì¸íŠ¸, ì„ íƒ)
- acceptance_criteria: |
  - [ ] Given... When... Then...
  - [ ] Given... When... Then...
  - [ ] Given... When... Then...
[/ISSUE_SUGGESTION]

## ê²€ì¦ í”„ë¡œì„¸ìŠ¤
ë³µìž¡í•œ ê¸°ëŠ¥ì— ëŒ€í•´ ì´ìŠˆë¥¼ ìƒì„±í•˜ê¸° ì „ì—, ì‚¬ìš©ìžì—ê²Œ í•µì‹¬ ì‚¬í•­ì„ Yes/No ì§ˆë¬¸ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤:

ì˜ˆì‹œ:
"ë‹¤ìŒ ë‚´ìš©ì´ ë§žëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”:
1. ë¡œê·¸ì¸ ê¸°ëŠ¥ì— ì†Œì…œ ë¡œê·¸ì¸(Google)ì´ í¬í•¨ë˜ë‚˜ìš”? (Yes/No)
2. ì´ë©”ì¼ ì¸ì¦ì´ í•„ìˆ˜ì¸ê°€ìš”? (Yes/No)
3. ë¹„ë°€ë²ˆí˜¸ ì°¾ê¸° ê¸°ëŠ¥ì´ í•„ìš”í•œê°€ìš”? (Yes/No)"

í™•ì¸ í›„ ìƒì„¸í•œ ì´ìŠˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## ëŒ€í™” ì‹œìž‘ ì‹œ
ì‚¬ìš©ìžê°€ ê¸°ëŠ¥ì´ë‚˜ ì•„ì´ë””ì–´ë¥¼ ì„¤ëª…í•˜ë©´:
1. í•µì‹¬ ìš”êµ¬ì‚¬í•­ íŒŒì•…ì„ ìœ„í•œ ëª…í™•í™” ì§ˆë¬¸ 2-3ê°œ
2. ê°„ë‹¨í•œ Yes/No í™•ì¸ìœ¼ë¡œ ë²”ìœ„ ì •ì˜
3. ë² ìŠ¤íŠ¸ í”„ëž™í‹°ìŠ¤ ê¸°ë°˜ì˜ ìƒì„¸í•œ ì´ìŠˆ ì œì•ˆ`;

interface ChatMessage {
  role: "user" | "assistant" | "system";
  content: string;
}

interface RequestBody {
  messages: ChatMessage[];
  provider?: "anthropic" | "openai" | "gemini" | "auto" | "lovable";
  stream?: boolean;
  conversationId?: string;
  teamId?: string;
}

async function callAnthropic(messages: ChatMessage[], apiKey: string, stream: boolean) {
  return await fetch(AI_PROVIDERS.anthropic.url, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "x-api-key": apiKey,
      "anthropic-version": "2023-06-01",
    },
    body: JSON.stringify({
      model: AI_PROVIDERS.anthropic.model,
      max_tokens: 4096,
      system: SYSTEM_PROMPT,
      messages: messages
        .filter((m) => m.role !== "system")
        .map((m) => ({ role: m.role, content: m.content })),
      stream,
    }),
  });
}

async function callOpenAI(messages: ChatMessage[], apiKey: string, stream: boolean) {
  return await fetch(AI_PROVIDERS.openai.url, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: AI_PROVIDERS.openai.model,
      messages: [{ role: "system", content: SYSTEM_PROMPT }, ...messages],
      stream,
    }),
  });
}

async function callGemini(messages: ChatMessage[], apiKey: string) {
  const contents = messages.map((m) => ({
    role: m.role === "assistant" ? "model" : "user",
    parts: [{ text: m.content }],
  }));

  if (messages[0]?.role !== "system") {
    contents.unshift({
      role: "user",
      parts: [{ text: `System: ${SYSTEM_PROMPT}` }],
    });
  }

  return await fetch(`${AI_PROVIDERS.gemini.url}?key=${apiKey}`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      contents,
      generationConfig: { maxOutputTokens: 4096 },
    }),
  });
}

async function callLovable(messages: ChatMessage[], apiKey: string, stream: boolean) {
  return await fetch(AI_PROVIDERS.lovable.url, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: AI_PROVIDERS.lovable.model,
      messages: [{ role: "system", content: SYSTEM_PROMPT }, ...messages],
      stream,
    }),
  });
}

function selectProvider(
  userSettings:
    | { anthropic_api_key?: string; openai_api_key?: string; gemini_api_key?: string }
    | null,
  messageContent: string,
): { provider: string; apiKey: string } {
  const hasUserAnthropic = !!userSettings?.anthropic_api_key;
  const hasUserOpenAI = !!userSettings?.openai_api_key;
  const hasUserGemini = !!userSettings?.gemini_api_key;

  const anthropicSecret = Deno.env.get("ANTHROPIC_API_KEY");
  const openaiSecret = Deno.env.get("OPENAI_API_KEY");
  const geminiSecret = Deno.env.get("GEMINI_API_KEY");
  const lovableKey = Deno.env.get("LOVABLE_API_KEY");

  const isCodeRelated = /ì½”ë“œ|code|í”„ë¡œê·¸ëž˜ë°|ê°œë°œ|ë²„ê·¸|ì—ëŸ¬|í•¨ìˆ˜|API/i.test(messageContent);
  const isCreative = /ì•„ì´ë””ì–´|ë¸Œë ˆì¸ìŠ¤í† ë°|ì°½ì˜|ë””ìžì¸|ê¸°íš/i.test(messageContent);
  const isAnalytical = /ë¶„ì„|ë°ì´í„°|í†µê³„|ë¹„êµ|í‰ê°€/i.test(messageContent);

  if (isCodeRelated && hasUserAnthropic) {
    return { provider: "anthropic", apiKey: userSettings!.anthropic_api_key! };
  }
  if (isCreative && hasUserOpenAI) {
    return { provider: "openai", apiKey: userSettings!.openai_api_key! };
  }
  if (isAnalytical && hasUserGemini) {
    return { provider: "gemini", apiKey: userSettings!.gemini_api_key! };
  }

  if (hasUserAnthropic) return { provider: "anthropic", apiKey: userSettings!.anthropic_api_key! };
  if (hasUserOpenAI) return { provider: "openai", apiKey: userSettings!.openai_api_key! };
  if (hasUserGemini) return { provider: "gemini", apiKey: userSettings!.gemini_api_key! };

  if (anthropicSecret) return { provider: "anthropic", apiKey: anthropicSecret };
  if (openaiSecret) return { provider: "openai", apiKey: openaiSecret };
  if (geminiSecret) return { provider: "gemini", apiKey: geminiSecret };
  if (lovableKey) return { provider: "lovable", apiKey: lovableKey };

  return { provider: "lovable", apiKey: "" };
}

serve(async (req) => {
  console.log(`[lily-chat ${FUNCTION_VERSION}] ${req.method} ${new URL(req.url).pathname}`);

  if (req.method === "OPTIONS") {
    return new Response(null, { headers: { ...corsHeaders, "Cache-Control": "no-store" } });
  }

  if (req.method === "GET") {
    const diagnostics = {
      version: FUNCTION_VERSION,
      deployed_at: DEPLOYED_AT,
      status: "running",
      env: {
        SUPABASE_URL: !!Deno.env.get("SUPABASE_URL"),
        SUPABASE_SERVICE_ROLE_KEY: !!Deno.env.get("SUPABASE_SERVICE_ROLE_KEY"),
      },
      secrets: {
        ANTHROPIC_API_KEY: !!Deno.env.get("ANTHROPIC_API_KEY"),
        OPENAI_API_KEY: !!Deno.env.get("OPENAI_API_KEY"),
        GEMINI_API_KEY: !!Deno.env.get("GEMINI_API_KEY"),
        LOVABLE_API_KEY: !!Deno.env.get("LOVABLE_API_KEY"),
      },
      hint: "At least one secret must be 'true' for the chat to work.",
    };

    return new Response(JSON.stringify(diagnostics, null, 2), {
      headers: {
        ...corsHeaders,
        "Content-Type": "application/json",
        "Cache-Control": "no-store",
        "X-Function-Version": FUNCTION_VERSION,
      },
    });
  }

  if (req.method !== "POST") {
    return new Response(JSON.stringify({ error: `Method not allowed: ${req.method}`, version: FUNCTION_VERSION }), {
      status: 405,
      headers: { ...corsHeaders, "Content-Type": "application/json", "Cache-Control": "no-store" },
    });
  }

  try {
    let parsedBody: RequestBody;
    try {
      parsedBody = (await req.json()) as RequestBody;
    } catch (_e) {
      return new Response(
        JSON.stringify({
          error: "Invalid or empty JSON body. Send POST with { messages: [{role, content}], provider?, stream? }.",
          version: FUNCTION_VERSION,
        }),
        { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json", "Cache-Control": "no-store" } },
      );
    }

    const { messages, provider = "auto", stream = true, conversationId, teamId } = parsedBody;
    void conversationId;
    void teamId;

    if (!messages || messages.length === 0) {
      return new Response(JSON.stringify({ error: "Messages are required", version: FUNCTION_VERSION }), {
        status: 400,
        headers: { ...corsHeaders, "Content-Type": "application/json", "Cache-Control": "no-store" },
      });
    }

    const supabaseUrl = Deno.env.get("SUPABASE_URL");
    const supabaseServiceKey = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY");
    if (!supabaseUrl || !supabaseServiceKey) {
      console.error("Missing backend environment variables", {
        SUPABASE_URL: !!supabaseUrl,
        SUPABASE_SERVICE_ROLE_KEY: !!supabaseServiceKey,
        version: FUNCTION_VERSION,
      });
      return new Response(
        JSON.stringify({
          error: "Server configuration error: missing backend environment variables",
          version: FUNCTION_VERSION,
        }),
        { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json", "Cache-Control": "no-store" } },
      );
    }

    const supabase = createClient(supabaseUrl, supabaseServiceKey);

    const authHeader = req.headers.get("Authorization");
    let userId: string | null = null;
    let userSettings:
      | {
          anthropic_api_key?: string;
          openai_api_key?: string;
          gemini_api_key?: string;
          default_provider?: string;
          auto_mode_enabled?: boolean;
        }
      | null = null;

    if (authHeader) {
      const token = authHeader.replace("Bearer ", "");
      const {
        data: { user },
      } = await supabase.auth.getUser(token);
      userId = user?.id || null;

      if (userId) {
        const { data: settings } = await supabase
          .from("user_ai_settings")
          .select("*")
          .eq("user_id", userId)
          .single();
        userSettings = settings;
      }
    }

    let selectedProvider: string;
    let apiKey: string;

    const envAnthropic = Deno.env.get("ANTHROPIC_API_KEY") || "";
    const envOpenAI = Deno.env.get("OPENAI_API_KEY") || "";
    const envGemini = Deno.env.get("GEMINI_API_KEY") || "";
    const envLovable = Deno.env.get("LOVABLE_API_KEY") || "";

    if (provider === "auto" || (userSettings?.auto_mode_enabled && provider !== "lovable")) {
      const selection = selectProvider(userSettings, messages[messages.length - 1]?.content || "");
      selectedProvider = selection.provider;
      apiKey = selection.apiKey;
    } else if (provider === "anthropic") {
      selectedProvider = "anthropic";
      apiKey = userSettings?.anthropic_api_key || envAnthropic;
    } else if (provider === "openai") {
      selectedProvider = "openai";
      apiKey = userSettings?.openai_api_key || envOpenAI;
    } else if (provider === "gemini") {
      selectedProvider = "gemini";
      apiKey = userSettings?.gemini_api_key || envGemini;
    } else if (provider === "lovable") {
      selectedProvider = "lovable";
      apiKey = envLovable;
    } else {
      selectedProvider = "lovable";
      apiKey = envLovable;
    }

    if (!apiKey) {
      return new Response(
        JSON.stringify({
          error: "No API key available for the selected provider",
          provider: selectedProvider,
          hint:
            "Set the corresponding project secret (ANTHROPIC_API_KEY / OPENAI_API_KEY / GEMINI_API_KEY / LOVABLE_API_KEY) or use provider='auto'.",
          version: FUNCTION_VERSION,
        }),
        { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json", "Cache-Control": "no-store" } },
      );
    }

    let response: Response;
    let finalProvider = selectedProvider;

    switch (selectedProvider) {
      case "anthropic":
        response = await callAnthropic(messages, apiKey, stream);
        break;
      case "openai":
        response = await callOpenAI(messages, apiKey, stream);
        break;
      case "gemini":
        response = await callGemini(messages, apiKey);
        break;
      case "lovable":
      default:
        response = await callLovable(messages, apiKey, stream);
        break;
    }

    if (!response.ok) {
      const errorText = await response.text();
      console.error(`${selectedProvider} API error:`, response.status, errorText);

      if (response.status === 429) {
        return new Response(
          JSON.stringify({ error: "Rate limit exceeded. Please try again later.", provider: selectedProvider, version: FUNCTION_VERSION }),
          { status: 429, headers: { ...corsHeaders, "Content-Type": "application/json", "Cache-Control": "no-store" } },
        );
      }

      if (response.status === 402) {
        return new Response(
          JSON.stringify({ error: "Payment required. Please add credits to continue.", provider: selectedProvider, version: FUNCTION_VERSION }),
          { status: 402, headers: { ...corsHeaders, "Content-Type": "application/json", "Cache-Control": "no-store" } },
        );
      }

      const canFallbackToGateway = selectedProvider !== "lovable" && !!envLovable;
      const isAnthropicModelNotFound =
        selectedProvider === "anthropic" &&
        (response.status === 404 || response.status === 400) &&
        /not_found_error|model/i.test(errorText);

      if (canFallbackToGateway && (response.status >= 500 || isAnthropicModelNotFound)) {
        console.warn("Primary provider failed; falling back to gateway", {
          selectedProvider,
          status: response.status,
          version: FUNCTION_VERSION,
        });

        const fallbackResp = await callLovable(messages, envLovable, stream);
        if (fallbackResp.ok) {
          response = fallbackResp;
          finalProvider = "lovable";
        } else {
          const fbText = await fallbackResp.text();
          console.error("Gateway fallback API error:", fallbackResp.status, fbText);
          return new Response(
            JSON.stringify({
              error: `AI provider error: ${response.status}`,
              provider: selectedProvider,
              details: errorText.substring(0, 500),
              fallback: {
                provider: "lovable",
                status: fallbackResp.status,
                details: fbText.substring(0, 500),
              },
              version: FUNCTION_VERSION,
            }),
            { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json", "Cache-Control": "no-store" } },
          );
        }
      } else {
        return new Response(
          JSON.stringify({
            error: `AI provider error: ${response.status}`,
            provider: selectedProvider,
            details: errorText.substring(0, 500),
            version: FUNCTION_VERSION,
          }),
          { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json", "Cache-Control": "no-store" } },
        );
      }
    }

    if (finalProvider === "gemini") {
      const data = await response.json();
      const text = data.candidates?.[0]?.content?.parts?.[0]?.text || "";
      return new Response(JSON.stringify({ content: text, provider: finalProvider, version: FUNCTION_VERSION }), {
        headers: { ...corsHeaders, "Content-Type": "application/json", "Cache-Control": "no-store" },
      });
    }

    if (stream) {
      return new Response(response.body, {
        headers: {
          ...corsHeaders,
          "Content-Type": "text/event-stream",
          "Cache-Control": "no-store",
          "X-AI-Provider": finalProvider,
          "X-Function-Version": FUNCTION_VERSION,
        },
      });
    }

    const data = await response.json();
    let content = "";
    if (finalProvider === "anthropic") {
      content = data.content?.[0]?.text || "";
    } else {
      content = data.choices?.[0]?.message?.content || "";
    }

    return new Response(JSON.stringify({ content, provider: finalProvider, version: FUNCTION_VERSION }), {
      headers: { ...corsHeaders, "Content-Type": "application/json", "Cache-Control": "no-store" },
    });
  } catch (error) {
    console.error("Edge function error:", error);
    return new Response(
      JSON.stringify({
        error: error instanceof Error ? error.message : "Unknown error",
        version: FUNCTION_VERSION,
      }),
      { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json", "Cache-Control": "no-store" } },
    );
  }
});

